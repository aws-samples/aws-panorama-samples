{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "cffd59b9",
   "metadata": {},
   "source": [
    "# ONNX2TRT + Yolov5s"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8a2a3ae2",
   "metadata": {},
   "source": [
    "# Prerequisites"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9aaddd01",
   "metadata": {},
   "source": [
    "1. In a terminal session on this Jupyter notebook server, run `aws configure`. This allows this notebook server to access Panorama resources and deploy applications on your behalf.\n",
    "\n",
    "2. **VERY IMPORTANT** : This example will build the engine file with dynamic batch size ranges from 1 to 8. If you decide to use batch size larger than 4, please use ATLEAST 2 CAMERAS for this example.\n",
    "\n",
    "3. **PLEASE READ THE [README](README.md) INCLUDE WITH THIS BEFORE YOU START USING THIS NOTEBOOK**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b1c2f6f8",
   "metadata": {},
   "source": [
    "# Set up"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "352b4749",
   "metadata": {},
   "source": [
    "Import libraries for use with this notebook environment, you do not need these libraries when you write your application code."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "00f12da5",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Notebook parameters\n",
    "Global constants that help the notebook create Panorama resources on your behalf."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "82721929",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import boto3\n",
    "# application name\n",
    "app_name = 'onnx2trt_app'\n",
    "\n",
    "## package names and node names\n",
    "code_package_name = 'onnx2trt_app'\n",
    "camera_node_name = 'abstract_rtsp_media_source'\n",
    "\n",
    "# AWS account ID\n",
    "account_id = boto3.client(\"sts\").get_caller_identity()[\"Account\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d1034c1e",
   "metadata": {},
   "source": [
    "## Set up application\n",
    "\n",
    "Every application uses the creator's AWS Account ID as the prefix to uniquely identifies the application resources. Running `panorama-cli import-application` replaces the generic account Id with your account Id."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "96ef4328",
   "metadata": {},
   "outputs": [],
   "source": [
    "!cd ./{app_name} && panorama-cli import-application"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "220ba832-c623-4537-beaf-f571afa35faa",
   "metadata": {},
   "source": [
    "### Build Docker image from Dockerfile"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "702ff1ca-c7b3-402e-b741-4318a7f7eb50",
   "metadata": {},
   "source": [
    "Please open a terminal\n",
    "- If your panorama device is still using Panorama system software v4.3.x (JetPack4.4):\n",
    "    - go to ./dependencies/docker and run: `sudo docker build -t  trtpt36:latest .`\n",
    "- If your panorama device is using Panorama system software v5.0+ (Jetpack4.6.2):\n",
    "    - go to ./dependencies/docker_jp462 and run: `sudo docker build -t  trtpt36:latest .`"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "337238ff",
   "metadata": {},
   "source": [
    "### Build app with container"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "afc63216",
   "metadata": {},
   "outputs": [],
   "source": [
    "container_asset_name = 'onnx2trt_app'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "25f5b4b1",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%capture captured_output\n",
    "\n",
    "# Building container image. This process takes time (5min ~ 10min)\n",
    "# FIXME : without %%capture, browser tab crashes because of too much output from the command.\n",
    "\n",
    "!cd ./{app_name} && panorama-cli build \\\n",
    "    --container-asset-name {container_asset_name} \\\n",
    "    --package-path packages/{account_id}-{code_package_name}-1.0 --local-image\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "81c66f7d-70b6-411c-b86f-5256a47d8516",
   "metadata": {},
   "outputs": [],
   "source": [
    "stdout_lines = captured_output.stdout.splitlines()\n",
    "stderr_lines = captured_output.stderr.splitlines()\n",
    "print(\"     :\")\n",
    "print(\"     :\")\n",
    "for line in stdout_lines[-30:] + stderr_lines[-30:]:\n",
    "    print(line)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f2960686-b884-4c5e-b8f8-2b1af1d8f3e7",
   "metadata": {},
   "source": [
    "### Special flags in package.json\n",
    "\n",
    "* Step 1 : Before you deploy the application, open TF37_opengpu/onnx_37_app/packages/(account-id)-tf2_4_trt_app-1.0/package.json\n",
    "* Step 2 : Add the following flags to the package.json\n",
    "\n",
    "```\n",
    "\"requirements\": \n",
    "            [{\n",
    "                    \"type\" : \"hardware_access\",\n",
    "                    \"inferenceAccelerators\": [ \n",
    "                        {\n",
    "                            \"deviceType\": \"nvhost_gpu\",\n",
    "                            \"sharedResourcePolicy\": {\n",
    "                                \"policy\" : \"allow_all\"\n",
    "                            }\n",
    "                        }\n",
    "                    ]\n",
    "            }]\n",
    "```\n",
    "\n",
    "The assets should look something like this\n",
    "\n",
    "```\n",
    "\"assets\": [\n",
    "    {\n",
    "        \"name\": \"onnx2trt_app\",\n",
    "        \"implementations\": [\n",
    "            {\n",
    "                \"type\": \"container\",\n",
    "                \"assetUri\": \"9a49a98784f4571adacc417f00942dac7ef2e34686eef21dca9fcb7f4b7ffd70.tar.gz\",\n",
    "                \"descriptorUri\": \"4bab130ec48eea84e072d9fe813b947e9d9610b2924099036b0165026a91d306.json\",\n",
    "                \"requirements\": \n",
    "                [{\n",
    "                    \"type\" : \"hardware_access\",\n",
    "                    \"inferenceAccelerators\": [ \n",
    "                        {\n",
    "                            \"deviceType\": \"nvhost_gpu\",\n",
    "                            \"sharedResourcePolicy\": {\n",
    "                                \"policy\" : \"allow_all\"\n",
    "                            }\n",
    "                        }\n",
    "                    ]\n",
    "                }]\n",
    "            }\n",
    "        ]\n",
    "    }\n",
    "],\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f017081e",
   "metadata": {},
   "source": [
    "### Upload application to Panorama for deploying to devices"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e8bc1f3b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# This step takes some time, depending on your network environment.\n",
    "!cd ./{app_name} && pwd && panorama-cli package-application"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4a6794d7",
   "metadata": {},
   "source": [
    "### Ready for deploying to a device\n",
    "\n",
    "Congrats! Your app is now ready to deploy to a device. Next, you can continue in this notebook to deploy the app programmatically or you can go to the Panorama console and deploying using the AWS Console. The console makes it easier to select camera streams and select the devices you want to deploy to. Programmatic deployment is faster to complete and easier to automate."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e8e572a8",
   "metadata": {},
   "source": [
    "# Deploy app to device"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "03bf8839-12a1-40c3-ac94-acf0644c5327",
   "metadata": {},
   "source": [
    "* Step 1: Copy the contents of./graphs/onnx2trt_app/graph.json\n",
    "* Step 2 : Go to the AWS Panorama Console, click Deploy Application\n",
    "* Step 3 : Paste the contents you just copied\n",
    "* Step 4 : Select the device\n",
    "* Step 5: Select atleast 2 cameras if batch size > 4\n",
    "* Step 6: Configure the batch size with desired batch size.\n",
    "* Step 7 : Deploy\n",
    "\n",
    "The deployment should take about 30 minutes, after deployment it will takes 12 ~ 20 mins for engine build. After build, the engine will be cached so that rebooting the device does not require another build."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "92eca1c8",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "6e6b819e3d6ce1b3469d64c9a73b8e3d0cb3f61adff56e1d9ccf4e24747b687e"
  },
  "kernelspec": {
   "display_name": "Python 3.8.12 ('python3')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
